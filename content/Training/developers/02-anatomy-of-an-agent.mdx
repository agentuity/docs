---
title: "Module 2: The Anatomy of an Agent"
description: Understanding how agents work - planning, reasoning, tools, and memory
---

Now that you've built your first agent, let's dive deeper to understand what makes agents tick. We'll explore the core components that transform a simple script into an autonomous, intelligent system.

## The Agent Lifecycle

Every agent interaction follows a predictable lifecycle, from receiving a trigger to returning a response. Understanding this flow is crucial for building effective agents.

<Mermaid chart="
graph TD
    A[Trigger Event<br/>HTTP, Cron, Email, etc.] --> B[Parse Request<br/>Extract data and metadata]
    B --> C[Agent Handler<br/>Your agent/run function executes]
    C --> D[Process Logic<br/>Business logic and decisions]
    D --> E[Access Storage<br/>KV, Vector, Object store]
    E --> F[Generate Response<br/>JSON, text, binary, etc. or handoff to another agent]
    F --> G[Return to Caller<br/>Client receives result]
" />

Let's explore each phase:

### 1. Trigger Events

Agents spring into action when triggered. Agentuity supports multiple trigger types:

| Trigger Type | Description | Use Case |
|-------------|-------------|----------|
| **webhook** | HTTP endpoint call | REST APIs, external integrations |
| **cron** | Scheduled execution | Batch processing, periodic tasks |
| **manual** | Console/CLI invocation | Testing, one-off tasks |
| **agent** | Called by another agent | Multi-agent workflows |
| **sms** | SMS message received | Text-based interactions |
| **email** | Email received | Email automation |
| **queue** | Message queue event | Async processing |

Each trigger provides different metadata and context:

<CodeExample py={`from datetime import datetime
from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    # Identify the trigger type
    trigger = request.trigger

    if trigger == "webhook":
        # Handle HTTP request
        data = await request.data.json()
        context.logger.info(f"Webhook triggered with data: {data}")

    elif trigger == "cron":
        # Handle scheduled execution
        context.logger.info(f"Cron job running at {datetime.now()}")
        # No input data for cron triggers

    elif trigger == "agent":
        # Handle agent-to-agent call
        calling_agent = request.metadata.get("source_agent")
        context.logger.info(f"Called by agent: {calling_agent}")

    return response.json({
        "trigger_type": trigger,
        "processed_at": datetime.now().isoformat()
    })`} js={`import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  // Identify the trigger type
  const trigger = request.trigger;

  if (trigger === 'webhook') {
    // Handle HTTP request
    const data = await request.data.json();
    context.logger.info(\`Webhook triggered with data: \${JSON.stringify(data)}\`);

  } else if (trigger === 'cron') {
    // Handle scheduled execution
    context.logger.info(\`Cron job running at \${new Date().toISOString()}\`);
    // No input data for cron triggers

  } else if (trigger === 'agent') {
    // Handle agent-to-agent call
    const callingAgent = request.metadata.get('source_agent');
    context.logger.info(\`Called by agent: \${callingAgent}\`);
  }

  return response.json({
    trigger_type: trigger,
    processed_at: new Date().toISOString()
  });
}`} />

### 2. Request and Response Handling

Every agent receives a request and must return a response. The request contains the trigger data and metadata, while the response can be in various formats:

<CodeExample py={`from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    # Access request data in different formats

    # JSON data (most common)
    json_data = await request.data.json()

    # Plain text
    text_data = await request.data.text()

    # Binary data
    binary_data = await request.data.binary()

    # Response options

    # JSON response (most common)
    return response.json({"result": "success"})

    # Text response
    # return response.text("Hello, World!")

    # HTML response
    # return response.html("<h1>Hello</h1>")

    # Binary response (for files)
    # return response.binary(file_bytes)

    # Redirect to another agent
    # return response.handoff({"name": "other-agent"}, data, metadata={})`} js={`import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  // Access request data in different formats

  // JSON data (most common)
  const jsonData = await request.data.json();

  // Plain text
  const textData = await request.data.text();

  // Binary data
  const binaryData = await request.data.binary();

  // Response options

  // JSON response (most common)
  return response.json({ result: 'success' });

  // Text response
  // return response.text('Hello, World!');

  // HTML response
  // return response.html('<h1>Hello</h1>');

  // Binary response (for files)
  // return response.binary(fileBytes);

  // Redirect to another agent
  // return response.handoff({ name: 'other-agent' }, { data: jsonData, contentType: 'application/json' });
}`} />

### 3. The Agent Context

The context object is your agent's gateway to Agentuity's services. It provides access to storage, logging, tracing, agent communication, and more:

<CodeExample py={`from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    # Logging at different levels
    context.logger.debug("Debug information")
    context.logger.info("General information")
    context.logger.warn("Warning message")
    context.logger.error("Error occurred")

    # Access metadata
    agent_id = context.agent.id
    agent_name = context.agent.name
    project_id = context.projectId
    session_id = context.sessionId

    # Key-Value storage
    await context.kv.set("cache", "key", {"data": "value"})
    result = await context.kv.get("cache", "key")

    # Vector storage for semantic search
    await context.vector.upsert("docs", [{
        "key": "doc1",
        "document": "AI agents are autonomous systems",
        "metadata": {"category": "intro"}
    }])

    # Object storage for files
    await context.objectstore.put("files", "report.pdf", pdf_bytes)

    # Get reference to another agent for inter-agent communication
    other_agent = context.get_agent("specialist-agent")
    # agent_response = await other_agent.run({"data": "Hello from triage agent"})

    return response.json({
        "agent": agent_name,
        "session": session_id
    })`} js={`import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  // Logging at different levels
  context.logger.debug('Debug information');
  context.logger.info('General information');
  context.logger.warn('Warning message');
  context.logger.error('Error occurred');

  // Access metadata
  const agentId = context.agent.id;
  const agentName = context.agent.name;
  const projectId = context.projectId;
  const sessionId = context.sessionId;

  // Key-Value storage
  await context.kv.set('cache', 'key', { data: 'value' });
  const result = await context.kv.get('cache', 'key');

  // Vector storage for semantic search
  await context.vector.upsert('docs', [{
    key: 'doc1',
    document: 'AI agents are autonomous systems',
    metadata: { category: 'intro' }
  }]);

  // Object storage for files
  await context.objectstore.put('files', 'report.pdf', pdfBytes);

  // Get reference to another agent for inter-agent communication
  const otherAgent = context.getAgent({ name: 'specialist-agent' });
  // const agentResponse = await otherAgent.run({ data: 'Hello from triage agent' });

  return response.json({
    agent: agentName,
    session: sessionId
  });
}`} />

## Planning and Reasoning: The Agent's Brain

What separates agents from simple scripts is their ability to plan and reason. While Agentuity provides the infrastructure, you implement the intelligence.

### The Planning Phase

Planning is how agents break down complex requests into actionable steps. According to [OpenAI's practical guide to building agents](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf), providing smaller, clearer steps from dense resources helps minimize ambiguity and helps the model better follow instructions. Effective agent planning involves:

1. **Intent Recognition**: Understanding what the user actually wants
2. **Task Decomposition**: Breaking complex requests into smaller steps
3. **Resource Assessment**: Determining what tools and data are needed
4. **Execution Strategy**: Deciding the order and approach for each step

Modern agents use LLMs for dynamic planning rather than hard-coded decision trees, allowing them to adapt their approach based on context and available resources.

### The Reasoning Loop

The reasoning loop is where agents continuously evaluate and adapt their approach. [Stanford's research on ReAct agents](https://arxiv.org/abs/2210.03629) shows that combining reasoning and acting in iterative loops significantly improves agent performance.

The basic pattern follows:
1. **Observe**: Analyze current state and available information
2. **Think**: Reason about the best next action
3. **Act**: Execute the chosen action
4. **Reflect**: Evaluate the results and learn
5. **Repeat**: Continue until goal is achieved or constraints are met

This iterative approach allows agents to handle uncertainty and recover from errors - key capabilities that distinguish agents from simple scripts.

## Tool Invocation: Extending Agent Capabilities

Agents become powerful when they can use external tools and services:

<CodeExample py={`import httpx
import os
from typing import Dict, Any
from agentuity import AgentRequest, AgentResponse, AgentContext

async def use_web_search(query: str, context: AgentContext) -> Dict[str, Any]:
    """Search the web using a real API."""
    try:
        # Example using a hypothetical search API
        api_key = os.getenv("SEARCH_API_KEY")
        if not api_key:
            context.logger.warn("No search API key found")
            return {"error": "Search not available"}

        async with httpx.AsyncClient() as client:
            response = await client.get(
                "https://api.searxng.org/search",
                params={"q": query, "format": "json"}
            )
            return response.json()
    except Exception as e:
        context.logger.error(f"Search failed: {str(e)}")
        return {"error": "Search failed"}

async def call_another_agent(agent_name: str, data: dict, context: AgentContext) -> Dict[str, Any]:
    """Call another agent within the same project."""
    try:
        agent = context.get_agent(agent_name)
        result = await agent.run({
            "data": data,
            "contentType": "application/json"
        })
        return await result.data.json()
    except Exception as e:
        context.logger.error(f"Agent call failed: {str(e)}")
        return {"error": "Agent call failed"}

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    data = await request.data.json()
    tool = data.get("tool")

    if tool == "search":
        result = await use_web_search(data["query"], context)
    elif tool == "delegate":
        result = await call_another_agent(data["agent"], data["task"], context)
    else:
        result = {"error": "Unknown tool"}

    return response.json(result)`} js={`import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

async function useWebSearch(query: string, context: AgentContext): Promise<any> {
  try {
    // Example using a hypothetical search API
    const apiKey = process.env.SEARCH_API_KEY;
    if (!apiKey) {
      context.logger.warn('No search API key found');
      return { error: 'Search not available' };
    }

    const response = await fetch('https://api.searxng.org/search?' +
      new URLSearchParams({ q: query, format: 'json' }));
    return await response.json();
  } catch (error) {
    context.logger.error(\`Search failed: \${error}\`);
    return { error: 'Search failed' };
  }
}

async function callAnotherAgent(agentName: string, data: any, context: AgentContext): Promise<any> {
  try {
    const agent = context.getAgent({ name: agentName });
    const result = await agent.run({
      data,
      contentType: 'application/json'
    });
    return await result.data.json();
  } catch (error) {
    context.logger.error(\`Agent call failed: \${error}\`);
    return { error: 'Agent call failed' };
  }
}

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  const data = await request.data.json();
  const tool = data.tool;

  let result;
  if (tool === 'search') {
    result = await useWebSearch(data.query, context);
  } else if (tool === 'delegate') {
    result = await callAnotherAgent(data.agent, data.task, context);
  } else {
    result = { error: 'Unknown tool' };
  }

  return response.json(result);
}`} />

## Memory Patterns: How Agents Remember

Memory enables agents to learn and maintain state across interactions. The duration and type of memory depends on your use case and TTL settings.

### Session Memory
For temporary data that should expire:

<CodeExample py={`from datetime import datetime
from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    session_id = request.metadata.get("session_id")

    # Store temporary session data with TTL
    await context.kv.set(
        "sessions",
        session_id,
        {
            "messages": [],
            "user_preferences": {},
            "started_at": datetime.now().isoformat()
        },
        {"ttl": 3600}  # Expires in 1 hour
    )

    # Retrieve session data
    session_data = await context.kv.get("sessions", session_id)
    if session_data.exists:
        data = await session_data.data.json()
        context.logger.info(f"Session active for {len(data['messages'])} messages")`} js={`import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  const sessionId = request.metadata.get('session_id');

  // Store temporary session data with TTL
  await context.kv.set(
    'sessions',
    sessionId,
    {
      messages: [],
      user_preferences: {},
      timestamp: new Date().toISOString()
    },
    { ttl: 3600 } // Expires in 1 hour
  );
}`} />

### Persistent Memory
For data that should survive restarts:

<CodeExample py={`from datetime import datetime
from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    user_id = request.metadata.get("user_id")

    # Store user preferences permanently (no TTL)
    await context.kv.set(
        "user_profiles",
        user_id,
        {
            "name": "Alice",
            "preferences": {"format": "concise"},
            "created_at": datetime.now().isoformat()
        }
        # No TTL = permanent storage
    )

    # Store large files in object storage
    await context.objectstore.put(
        "user_documents",
        f"{user_id}/resume.pdf",
        pdf_bytes
    )`} js={`import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  const userId = request.metadata.get('user_id');

  // Store user preferences permanently (no TTL)
  await context.kv.set(
    'user_profiles',
    userId,
    {
      name: 'Alice',
      preferences: { format: 'concise' },
      created_at: new Date().toISOString()
    }
    // No TTL = permanent storage
  );

  // Store large files in object storage
  await context.objectstore.put(
    'user_documents',
    \`\${userId}/resume.pdf\`,
    pdfBytes
  );
}`} />

### Searchable Memory
For semantic search and knowledge retrieval:

<CodeExample py={`from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    # Store searchable knowledge
    await context.vector.upsert("knowledge", [{
        "key": "user_feedback_001",
        "document": "Users prefer concise responses with examples",
        "metadata": {
            "learned_from": "user_feedback",
            "confidence": 0.85,
            "category": "response_style"
        }
    }])

    # Search for relevant knowledge
    results = await context.vector.search(
        "knowledge",
        "How should I format my responses?",
        limit=5
    )

    # Use the knowledge to improve responses
    if results:
        context.logger.info(f"Found {len(results)} relevant insights")
        for result in results:
            context.logger.info(f"Insight: {result.document}")`} js={`import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  // Store searchable knowledge
  await context.vector.upsert('knowledge', [{
    key: 'user_feedback_001',
    document: 'Users prefer concise responses with examples',
    metadata: {
      learned_from: 'user_feedback',
      confidence: 0.85,
      category: 'response_style'
    }
  }]);

  // Search for relevant knowledge
  const results = await context.vector.search(
    'knowledge',
    'How should I format my responses?',
    { limit: 5 }
  );

  // Use the knowledge to improve responses
  if (results.length > 0) {
    context.logger.info(\`Found \${results.length} relevant insights\`);
    results.forEach(result => {
      context.logger.info(\`Insight: \${result.document}\`);
    });
  }
}`} />

## Framework Awareness: Choosing the Right Tool

<Callout type="info">
Agentuity is framework-agnostic. You can use any AI framework or build custom agents from scratch.
</Callout>

### Popular Agent Frameworks

Different frameworks excel at different tasks. Here's when to use each:

| Framework | Best For | Language Support | Agentuity Integration |
|-----------|----------|------------------|----------------------|
| **LangChain** | Complex chains, RAG applications | Python, TypeScript | Native SDK support |
| **CrewAI** | Multi-agent teams, role-based systems | Python | Container deployment |
| **AutoGen** | Research, conversational AI | Python | Direct deployment |
| **Mastra** | TypeScript agents, workflows, modern DX | TypeScript | Full compatibility |
| **Vercel AI SDK** | UI-integrated agents, streaming, web apps | TypeScript | Direct integration |
| **Custom** | Specific requirements, full control | Python, TypeScript, Bun | Full platform features |

### Framework Comparison Example

Here's the same agent built with different approaches:

<CodeExample py={`# Vanilla Python Agent
from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    data = await request.data.json()
    # Direct implementation
    result = process_data(data)
    return response.json(result)

# LangChain Agent
from langchain.agents import initialize_agent
from langchain.llms import OpenAI
from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    llm = OpenAI()
    agent = initialize_agent(tools, llm, agent="zero-shot")
    result = agent.run(await request.data.text())
    return response.text(result)

# CrewAI Agent
from crewai import Agent, Task, Crew
from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    researcher = Agent(role="Researcher", goal="Find information")
    writer = Agent(role="Writer", goal="Create content")

    crew = Crew(agents=[researcher, writer])
    result = crew.kickoff(await request.data.json())
    return response.json(result)`} js={`// Vanilla TypeScript Agent
import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  const data = await request.data.json();
  // Direct implementation
  const result = processData(data);
  return response.json(result);
}

// LangChain Agent
import { initializeAgentExecutor } from 'langchain/agents';
import { OpenAI } from 'langchain/llms/openai';
import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  const llm = new OpenAI();
  const agent = await initializeAgentExecutor(tools, llm, 'zero-shot');
  const result = await agent.call({ input: await request.data.text() });
  return response.text(result.output);
}

// Custom Multi-Agent System
import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  const researcher = new Agent('Researcher', 'Find information');
  const writer = new Agent('Writer', 'Create content');

  const researchResult = await researcher.execute(data);
  const writeResult = await writer.execute(researchResult);
  return response.json(writeResult);
}`} />

### When to Use Which Framework

| Framework | Use When You Need | Avoid When You Need |
|-----------|-------------------|-------------------|
| **LangChain** | Complex reasoning chains, RAG applications, extensive data integrations | Simple agents, minimal dependencies, lightweight solutions |
| **CrewAI** | Multi-agent teams, role-based collaboration, specialized workflows | Single-agent tasks, simple request-response patterns |
| **AutoGen** | Conversational AI, research applications, experimental workflows | Production deployments, strict performance requirements |
| **Custom** | Full control, specific requirements, optimized performance | Rapid prototyping, standard use cases, extensive tooling needs |

## Lab: Building a Weather Agent with Multiple Triggers

Let's build an agent that demonstrates different behaviors based on how it's triggered - the same agent code serves different purposes depending on the trigger type.

### Key Implementation: Trigger-Based Routing

The core pattern shows how agents can behave differently based on their trigger:

<CodeExample py={`# Key pattern: Different behavior based on trigger type
async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    if request.trigger == "cron":
        # Bulk monitoring mode
        context.logger.info("Running scheduled weather monitoring")
        return await monitor_multiple_cities(context)
    else:
        # On-demand single query
        data = await request.data.json()
        location = data.get("location", "San Francisco, CA")
        return await get_single_weather(location, context)`} js={`// Key pattern: Different behavior based on trigger type
export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  if (request.trigger === 'cron') {
    // Bulk monitoring mode
    context.logger.info('Running scheduled weather monitoring');
    return await monitorMultipleCities(context);
  } else {
    // On-demand single query
    const data = await request.data.json();
    const location = data.location || 'San Francisco, CA';
    return await getSingleWeather(location, context);
  }
}`} />

### Key Implementation: External API Integration

Real-world agents integrate with external services using proper error handling:

<CodeExample py={`# Key pattern: NWS API two-step process with proper error handling
async def fetch_nws_weather(lat: float, lon: float, location_name: str, context: AgentContext):
    try:
        # Step 1: Get grid coordinates from lat/lon
        points_url = f"https://api.weather.gov/points/{lat},{lon}"

        async with aiohttp.ClientSession() as session:
            async with session.get(points_url, headers={"User-Agent": USER_AGENT},
                                 timeout=aiohttp.ClientTimeout(total=10)) as points_response:
                if points_response.status != 200:
                    raise Exception(f"NWS points API error: {points_response.status}")

                points_data = await points_response.json()
                grid_props = points_data.get("properties", {})

                # Extract and validate grid data
                grid_id = grid_props.get("gridId")
                grid_x = grid_props.get("gridX")
                grid_y = grid_props.get("gridY")

                if not all([grid_id, grid_x, grid_y]):
                    raise Exception("Invalid grid data from NWS points API")

            # Step 2: Get forecast using grid coordinates
            forecast_url = f"https://api.weather.gov/gridpoints/{grid_id}/{grid_x},{grid_y}/forecast"
            # ... fetch and process forecast data

    except Exception as e:
        context.logger.error(f"Weather API failed for {location_name}: {e}")
        raise`} js={`// Key pattern: NWS API two-step process with proper error handling
async function fetchNWSWeather(lat: number, lon: number, locationName: string, context: AgentContext): Promise<WeatherResult | null> {
  try {
    // Step 1: Get grid coordinates from lat/lon
    const pointsUrl = \`https://api.weather.gov/points/\${lat},\${lon}\`;

    const pointsResponse = await fetch(pointsUrl, {
      headers: { 'User-Agent': USER_AGENT },
      signal: AbortSignal.timeout(10000)  // 10 second timeout
    });

    if (!pointsResponse.ok) {
      throw new Error(\`NWS points API failed: \${pointsResponse.status} \${pointsResponse.statusText}\`);
    }

    const pointsData = await pointsResponse.json() as NWSPointsResponse;
    const gridProps = pointsData.properties;

    // Validate and extract grid properties
    if (!gridProps || gridProps.gridId === undefined || gridProps.gridX === undefined || gridProps.gridY === undefined) {
      throw new Error('Could not extract grid information from NWS points API response.');
    }

    // Step 2: Get forecast using grid coordinates
    const forecastUrl = \`https://api.weather.gov/gridpoints/\${gridProps.gridId}/\${gridProps.gridX},\${gridProps.gridY}/forecast\`;
    // ... fetch and process forecast data

  } catch (error) {
    context.logger.error(\`Weather API failed for \${locationName}: \${error}\`);
    throw new Error(\`Weather service unavailable: \${error instanceof Error ? error.message : 'Unknown error'}\`);
  }
}`} />

### Key Implementation: Smart Caching Strategies

Different caching approaches based on use case and trigger:

<CodeExample py={`# Key pattern: Trigger-based caching with different TTL strategies
async def handle_manual_trigger(request: AgentRequest, response: AgentResponse, context: AgentContext):
    # Parse location and create cache key
    location_query = await request.data.text() or "San Francisco"
    cache_key = f"city_{location_query.lower().replace(' ', '_')}"

    # Check cache first (5 minutes for manual requests)
    cached = await context.kv.get("weather", cache_key)
    if cached.exists:
        cached_weather = await cached.data.json()
        context.logger.info(f"Returning cached weather for {location_query}")
        return response.json(cached_weather)

    # Resolve location to coordinates (geocoding step)
    coordinates = await geocode_location(location_query)
    if not coordinates:
        return response.json({"error": "Unable to find location coordinates"})

    # Fetch fresh data and cache with shorter TTL
    weather = await fetch_nws_weather(coordinates["lat"], coordinates["lon"], location_query, context)
    await context.kv.set("weather", cache_key, weather, {"ttl": 300})  # 5 minutes

    return response.json(weather)

async def handle_cron_trigger(response: AgentResponse, context: AgentContext):
    # Bulk processing with longer cache (1 hour for monitoring)
    for city in MONITORED_CITIES:
        weather = await fetch_nws_weather(city["lat"], city["lon"], city["name"], context)
        await context.kv.set("weather", f"city_{city['name'].lower()}", weather, {"ttl": 3600})
        context.logger.info(f"Cached weather for {city['name']}: {weather['temperature']}°F")`} js={`// Key pattern: Trigger-based caching with different TTL strategies
async function handleManualTrigger(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  // Parse location and create cache key
  const locationQuery = await request.data.text() || 'San Francisco';
  const cacheKey = \`city_\${locationQuery.toLowerCase().replace(/\\s+/g, '_')}\`;

  // Check cache first (5 minutes for manual requests)
  const cached = await context.kv.get('weather', cacheKey);
  if (cached.exists) {
    const cachedWeather = await cached.data.json() as WeatherResult;
    context.logger.info(\`Returning cached weather for \${locationQuery}\`);
    return response.json(cachedWeather);
  }

  // Resolve location to coordinates (geocoding step)
  const coordinates = await geocodeLocation(locationQuery);
  if (!coordinates) {
    return response.json({ error: 'Unable to find location coordinates' });
  }

  // Fetch fresh data and cache with shorter TTL
  const weather = await fetchNWSWeather(coordinates.lat, coordinates.lon, locationQuery, context);
  await context.kv.set('weather', cacheKey, weather, { ttl: 300 }); // 5 minutes

  return response.json(weather);
}

async function handleCronTrigger(response: AgentResponse, context: AgentContext) {
  // Bulk processing with longer cache (1 hour for monitoring)
  for (const city of MONITORED_CITIES) {
    const weather = await fetchNWSWeather(city.lat, city.lon, city.name, context);
    await context.kv.set('weather', \`city_\${city.name.toLowerCase()}\`, weather, { ttl: 3600 });
    context.logger.info(\`Cached weather for \${city.name}: \${weather.temperature}°F\`);
  }
}`} />

### Build This Agent Yourself

Ready to implement this agent? Follow our complete examples:

<div className="flex flex-wrap gap-3 mb-6">
  <a href="https://github.com/agentuity/examples/tree/add-tutorials/training/02-weather-agent-ts" target="_blank" rel="noopener noreferrer"
     className="inline-flex items-center gap-2 px-4 py-3 bg-gray-900 text-white rounded-lg hover:bg-gray-800 transition-colors no-underline text-sm font-medium">
    <svg className="w-4 h-4" fill="currentColor" viewBox="0 0 20 20"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
    TypeScript
  </a>
  <a href="https://github.com/agentuity/examples/tree/add-tutorials/training/02_weather_agent_py" target="_blank" rel="noopener noreferrer"
     className="inline-flex items-center gap-2 px-4 py-3 bg-gray-900 text-white rounded-lg hover:bg-gray-800 transition-colors no-underline text-sm font-medium">
    <svg className="w-4 h-4" fill="currentColor" viewBox="0 0 20 20"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
    Python
  </a>
</div>

### What This Agent Demonstrates

- **Trigger-based behavior**: Same agent code behaves differently based on trigger type
- **External API integration**: Real National Weather Service API calls with proper error handling
- **Smart caching strategies**: Different TTL based on use case (cron vs manual)
- **Production patterns**: Timeouts, defensive typing, comprehensive logging
- **AI enhancement**: Vercel AI SDK for weather interpretation

The complete examples show you how to build real agents that integrate external APIs and use multiple triggers with caching and error handling.

## Testing Your Weather Agent

1. **Start DevMode:**
```bash
agentuity dev
```

2. **Test the weather agent** with different city names and trigger types
3. **Monitor the execution** in the Logs and Sessions tabs to see caching behavior

### Configuring Cron Triggers for Production

For actual scheduled execution, configure cron triggers through the [Agentuity Console](https://app.agentuity.com):

1. Navigate to your agent in the Console
2. Click on **"Add Trigger"** and select **"Cron Job"**
3. Configure the schedule using cron syntax (e.g., `0 * * * *` for hourly)
4. Set the Content Type and optional Payload
5. Enable the trigger and save

<Callout type="info">
Learn more about configuring triggers in the [Agent Configuration Guide](/Cloud/agents).
</Callout>

## Performance Considerations

Building efficient agents requires thinking about performance from the start:

### Cost Optimization

Effective cost optimization strategies include:

- **Cache frequently used data** in KV storage to reduce repeated processing
- **Batch operations** when possible to minimize API calls
- **Use appropriate LLM models** - use reasoning models only when you need complex reasoning
- **Consider fast inference providers** - Groq offers high-speed inference for many models
- **Implement early exits** in reasoning loops to avoid unnecessary iterations

### Latency vs. Capability Trade-offs

Different approaches offer varying trade-offs between speed and intelligence:

| Approach | Latency | Capability | Use Case |
|----------|---------|------------|----------|
| Simple rules | Fastest | Low | Basic routing, simple classification |
| Small LLM | Fast | Medium | Text classification, simple reasoning |
| Large LLM | Moderate | High | Complex reasoning, nuanced understanding |
| Multi-agent | Slowest | Very High | Research, complex workflows |

<CodeExample py={`from agentuity import AgentRequest, AgentResponse, AgentContext

async def run(request: AgentRequest, response: AgentResponse, context: AgentContext):
    data = await request.data.json()
    complexity = assess_complexity(data)
    
    if complexity == "simple":
        # Use rules-based approach
        result = apply_rules(data)
        return response.json(result)
    
    elif complexity == "medium":
        # Use small, fast model
        result = await small_model_process(data)
        return response.json(result)
    
    else:
        # Use full agent capabilities
        result = await full_agent_process(data, context)
        return response.json(result)`} js={`import type { AgentRequest, AgentResponse, AgentContext } from "@agentuity/sdk";

export default async function Agent(request: AgentRequest, response: AgentResponse, context: AgentContext) {
  const data = await request.data.json();
  const complexity = assessComplexity(data);

  if (complexity === 'simple') {
    // Use rules-based approach
    const result = applyRules(data);
    return response.json(result);

  } else if (complexity === 'medium') {
    // Use small, fast model
    const result = await smallModelProcess(data);
    return response.json(result);

  } else {
    // Use full agent capabilities
    const result = await fullAgentProcess(data, context);
    return response.json(result);
  }
}`} />

## Key Takeaways

- **Agents follow a lifecycle**: Trigger → Plan → Reason → Execute → Remember → Respond
- **Multiple trigger types**: Choose the right trigger for your use case
- **Context is powerful**: It provides access to all Agentuity services
- **Frameworks are tools**: Pick the right one for your needs, or go custom
- **Memory patterns matter**: Session data (TTL), persistent data (no TTL), searchable knowledge (Vector)
- **Performance matters**: Balance capability with cost and latency

## What's Next?

You now understand the core components that make agents work. In the next module, we'll dive deep into memory systems - how agents remember, learn, and improve over time.

But first, experiment with the weather agent:
- Test it with different cities
- Try the caching behavior with repeated requests
- Add new cities to the cron batch update
- Modify the cache TTL and observe the difference

Remember: The anatomy you've learned here is the foundation. The intelligence you add on top is what makes your agents unique.

---

**Ready for Module 3?** [Agent Memory](./03-agent-memory)
